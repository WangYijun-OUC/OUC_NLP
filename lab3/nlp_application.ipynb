{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a640b91-e37e-4d6d-8231-140b642e7015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current context loaded:\n",
      " mode: 0\n",
      " device_target: CPU\n"
     ]
    }
   ],
   "source": [
    "import argparse \n",
    "from mindspore import context \n",
    "from easydict import EasyDict as edict \n",
    "# LSTM CONFIG \n",
    "lstm_cfg = edict({ \n",
    "    'num_classes': 2, \n",
    "    'learning_rate': 0.1, \n",
    "    'momentum': 0.9, \n",
    "    'num_epochs': 10, \n",
    "    'batch_size': 64, \n",
    "    'embed_size': 300, \n",
    "    'num_hiddens': 100, \n",
    "    'num_layers': 2, \n",
    "    'bidirectional': True, \n",
    "    'save_checkpoint_steps': 390, \n",
    "    'keep_checkpoint_max': 10 \n",
    "    })\n",
    "cfg = lstm_cfg \n",
    "parser = argparse.ArgumentParser(description='MindSpore LSTM Example') \n",
    "parser.add_argument('--preprocess', type=str, default='false', choices=['true', 'false'], help='whether to preprocess data.') \n",
    "parser.add_argument('--aclimdb_path', type=str, default=\"./datasets/aclImdb\", help='path where the dataset is stored.') \n",
    "parser.add_argument('--glove_path', type=str, default=\"./datasets/glove\", help='path where the GloVe is stored.') \n",
    "parser.add_argument('--preprocess_path', type=str, default=\"./preprocess\", help='path where the pre-process data is stored.') \n",
    "parser.add_argument('--ckpt_path', type=str, default=\"./models/ckpt/nlp_application\", help='the path to save the checkpoint file.') \n",
    "parser.add_argument('--pre_trained', type=str, default=None, help='the pretrained checkpoint file path.') \n",
    "parser.add_argument('--device_target', type=str, default=\"GPU\", choices=['GPU', 'CPU'], help='the target device to run, support \"GPU\", \"CPU\". Default: \"GPU\".') \n",
    "args = parser.parse_args(['--device_target', 'CPU', '--preprocess', 'true']) \n",
    "context.set_context( mode=context.GRAPH_MODE, save_graphs=False, device_target=args.device_target) \n",
    "print(\"Current context loaded:\\n mode: {}\\n device_target: {}\".format(context.get_context(\"mode\"), context.get_context(\"device_target\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5951d6d9-039a-4c49-8b4b-36752efef85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Data Pre-processing ==============\n",
      "======================= Successful =======================\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from itertools import chain \n",
    "import numpy as np \n",
    "import gensim \n",
    "from mindspore.mindrecord import FileWriter\n",
    "\n",
    "class ImdbParser(): \n",
    "    \"\"\" \n",
    "    parse aclImdb data to features and labels. \n",
    "    sentence->tokenized->encoded->padding->features \n",
    "    \"\"\" \n",
    "    \n",
    "    def __init__(self, imdb_path, glove_path, embed_size=300): \n",
    "        self.__segs = ['train', 'test'] \n",
    "        self.__label_dic = {'pos': 1, 'neg': 0} \n",
    "        self.__imdb_path = imdb_path \n",
    "        self.__glove_dim = embed_size \n",
    "        self.__glove_file = os.path.join(glove_path, 'glove.6B.' + str(self.__glove_dim) + 'd.txt') \n",
    "        \n",
    "        # properties \n",
    "        self.__imdb_datas = {} \n",
    "        self.__features = {} \n",
    "        self.__labels = {} \n",
    "        self.__vacab = {} \n",
    "        self.__word2idx = {} \n",
    "        self.__weight_np = {} \n",
    "        self.__wvmodel = None \n",
    "        \n",
    "    def parse(self): \n",
    "        \"\"\" \n",
    "        parse imdb data to memory \n",
    "        \"\"\" \n",
    "        self.__wvmodel = gensim.models.KeyedVectors.load_word2vec_format(self.__glove_file) \n",
    "        for seg in self.__segs: \n",
    "            self.__parse_imdb_datas(seg) \n",
    "            self.__parse_features_and_labels(seg)\n",
    "            self.__gen_weight_np(seg) \n",
    "    def __parse_imdb_datas(self, seg): \n",
    "        \"\"\" \n",
    "        load data from txt \n",
    "        \"\"\" \n",
    "        data_lists = [] \n",
    "        for label_name, label_id in self.__label_dic.items(): \n",
    "            sentence_dir = os.path.join(self.__imdb_path, seg, label_name) \n",
    "            for file in os.listdir(sentence_dir): \n",
    "                with open(os.path.join(sentence_dir, file), mode='r', encoding='utf8') as f:\n",
    "                    sentence = f.read().replace('\\n', '') \n",
    "                    data_lists.append([sentence, label_id]) \n",
    "        self.__imdb_datas[seg] = data_lists \n",
    "    \n",
    "    def __parse_features_and_labels(self, seg): \n",
    "        \"\"\" \n",
    "        parse features and labels\n",
    "        \"\"\" \n",
    "        features = [] \n",
    "        labels = [] \n",
    "        for sentence, label in self.__imdb_datas[seg]: \n",
    "            features.append(sentence) \n",
    "            labels.append(label) \n",
    "        self.__features[seg] = features \n",
    "        self.__labels[seg] = labels \n",
    "        \n",
    "        # update feature to tokenized \n",
    "        self.__updata_features_to_tokenized(seg) \n",
    "        # parse vacab \n",
    "        self.__parse_vacab(seg) \n",
    "        # encode feature \n",
    "        self.__encode_features(seg) \n",
    "        # padding feature \n",
    "        self.__padding_features(seg) \n",
    "    \n",
    "    def __updata_features_to_tokenized(self, seg):\n",
    "        tokenized_features = [] \n",
    "        for sentence in self.__features[seg]: \n",
    "            tokenized_sentence = [word.lower() for word in sentence.split(\" \")] \n",
    "            tokenized_features.append(tokenized_sentence) \n",
    "        self.__features[seg] = tokenized_features \n",
    "    def __parse_vacab(self, seg): \n",
    "        # vocab \n",
    "        tokenized_features = self.__features[seg] \n",
    "        vocab = set(chain(*tokenized_features)) \n",
    "        self.__vacab[seg] = vocab \n",
    "        # word_to_idx: {'hello': 1, 'world':111, ... '<unk>': 0} \n",
    "        word_to_idx = {word: i + 1 for i, word in enumerate(vocab)} \n",
    "        word_to_idx['<unk>'] = 0 \n",
    "        self.__word2idx[seg] = word_to_idx \n",
    "        \n",
    "    def __encode_features(self, seg): \n",
    "        \"\"\" encode word to index \"\"\"\n",
    "        word_to_idx = self.__word2idx['train'] \n",
    "        encoded_features = [] \n",
    "        for tokenized_sentence in self.__features[seg]: \n",
    "            encoded_sentence = [] \n",
    "            for word in tokenized_sentence: \n",
    "                encoded_sentence.append(word_to_idx.get(word, 0)) \n",
    "            encoded_features.append(encoded_sentence) \n",
    "        self.__features[seg] = encoded_features \n",
    "    \n",
    "    def __padding_features(self, seg, maxlen=500, pad=0): \n",
    "        \"\"\" pad all features to the same length \"\"\"\n",
    "        padded_features = [] \n",
    "        for feature in self.__features[seg]: \n",
    "            if len(feature) >= maxlen: \n",
    "                padded_feature = feature[:maxlen] \n",
    "            else:\n",
    "                padded_feature = feature \n",
    "                while len(padded_feature) < maxlen: \n",
    "                    padded_feature.append(pad) \n",
    "            padded_features.append(padded_feature) \n",
    "        self.__features[seg] = padded_features \n",
    "                \n",
    "    def __gen_weight_np(self, seg): \n",
    "        \"\"\" \n",
    "        generate weight by gensim \n",
    "        \"\"\" \n",
    "        weight_np = np.zeros((len(self.__word2idx[seg]), self.__glove_dim), dtype=np.float32) \n",
    "        for word, idx in self.__word2idx[seg].items(): \n",
    "            if word not in self.__wvmodel: \n",
    "                continue \n",
    "            word_vector = self.__wvmodel.get_vector(word) \n",
    "            weight_np[idx, :] = word_vector \n",
    "        self.__weight_np[seg] = weight_np \n",
    "    def get_datas(self, seg): \n",
    "        \"\"\" return features, labels, and weight \"\"\" \n",
    "        features = np.array(self.__features[seg]).astype(np.int32) \n",
    "        labels = np.array(self.__labels[seg]).astype(np.int32) \n",
    "        weight = np.array(self.__weight_np[seg]) \n",
    "        return features, labels, weight \n",
    "def _convert_to_mindrecord(data_home, features, labels, weight_np=None, training=True): \n",
    "    \"\"\" convert imdb dataset to mindrecoed dataset \"\"\" \n",
    "    if weight_np is not None: \n",
    "        np.savetxt(os.path.join(data_home, 'weight.txt'), weight_np) \n",
    "    # write mindrecord \n",
    "    schema_json = {\"id\": {\"type\": \"int32\"}, \n",
    "                   \"label\": {\"type\": \"int32\"},\n",
    "                   \"feature\": {\"type\": \"int32\", \"shape\": [-1]}} \n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord\") \n",
    "    if not training: \n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord\") \n",
    "    def get_imdb_data(features, labels): \n",
    "        data_list = [] \n",
    "        for i, (label, feature) in enumerate(zip(labels, features)): \n",
    "            data_json = {\"id\": i, \n",
    "                         \"label\": int(label), \n",
    "                         \"feature\": feature.reshape(-1)} \n",
    "            data_list.append(data_json) \n",
    "        return data_list \n",
    "    writer = FileWriter(data_dir, shard_num=4) \n",
    "    data = get_imdb_data(features, labels) \n",
    "    writer.add_schema(schema_json, \"nlp_schema\") \n",
    "    writer.add_index([\"id\", \"label\"]) \n",
    "    writer.write_raw_data(data) \n",
    "    writer.commit() \n",
    "def convert_to_mindrecord(embed_size, aclimdb_path, preprocess_path, glove_path): \n",
    "    \"\"\" convert imdb dataset to mindrecoed dataset \"\"\" \n",
    "    parser = ImdbParser(aclimdb_path, glove_path, embed_size) \n",
    "    parser.parse() \n",
    "    if not os.path.exists(preprocess_path): \n",
    "        print(f\"preprocess path {preprocess_path} is not exist\") \n",
    "        os.makedirs(preprocess_path) \n",
    "    train_features, train_labels, train_weight_np = parser.get_datas('train') \n",
    "    _convert_to_mindrecord(preprocess_path, train_features, train_labels, train_weight_np) \n",
    "    test_features, test_labels, _ = parser.get_datas('test') \n",
    "    _convert_to_mindrecord(preprocess_path, test_features, test_labels, training=False) \n",
    "if args.preprocess == \"true\": \n",
    "    os.system(\"rm -f ./preprocess/aclImdb* weight*\") \n",
    "    print(\"============== Starting Data Pre-processing ==============\") \n",
    "    convert_to_mindrecord(cfg.embed_size, args.aclimdb_path, args.preprocess_path, args.glove_path) \n",
    "    print(\"======================= Successful =======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f045e964-ecfb-4860-8951-6113b2fe6d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current context loaded:\n",
      " mode: 0\n",
      " device_target: CPU\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5796ef8-c348-48fe-ac8e-b477b7d8b107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first batch contains label below:\n",
      "[0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0]\n",
      "\n",
      "The feature of the first item in the first batch is below\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import mindspore.dataset as ds \n",
    "def lstm_create_dataset(data_home, batch_size, repeat_num=1, training=True): \n",
    "    \"\"\"Data operations.\"\"\" \n",
    "    ds.config.set_seed(1) \n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord0\")\n",
    "    if not training: \n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord0\") \n",
    "    data_set = ds.MindDataset(data_dir, columns_list=[\"feature\", \"label\"], num_parallel_workers=4) \n",
    "    # apply map operations on images \n",
    "    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size()) \n",
    "    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True) \n",
    "    data_set = data_set.repeat(count=repeat_num) \n",
    "    return data_set \n",
    "ds_train = lstm_create_dataset(args.preprocess_path, cfg.batch_size) \n",
    "iterator = next(ds_train.create_dict_iterator()) \n",
    "first_batch_label = iterator[\"label\"].asnumpy() \n",
    "first_batch_first_feature = iterator[\"feature\"].asnumpy()[0] \n",
    "print(f\"The first batch contains label below:\\n{first_batch_label}\\n\") \n",
    "print(f\"The feature of the first item in the first batch is below\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d812702-d3b8-44d6-9382-11e3c3e2a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('embedding.embedding_table', Parameter (name=embedding.embedding_table, shape=(252193, 300), dtype=Float32, requires_grad=False)), ('encoder.weight0', Parameter (name=encoder.weight0, shape=(320800, 1, 1), dtype=Float32, requires_grad=True)), ('encoder.weight1', Parameter (name=encoder.weight1, shape=(240800, 1, 1), dtype=Float32, requires_grad=True)), ('decoder.weight', Parameter (name=decoder.weight, shape=(2, 400), dtype=Float32, requires_grad=True)), ('decoder.bias', Parameter (name=decoder.bias, shape=(2,), dtype=Float32, requires_grad=True))])\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "import numpy as np \n",
    "from mindspore import Tensor, nn, context, Parameter, ParameterTuple \n",
    "from mindspore.common.initializer import initializer \n",
    "import mindspore.ops as ops \n",
    "STACK_LSTM_DEVICE = [\"CPU\"] \n",
    "# Initialize short-term memory (h) and long-term memory (c) to 0 \n",
    "def lstm_default_state(batch_size, hidden_size, num_layers, bidirectional): \n",
    "    \"\"\"init default input.\"\"\" \n",
    "    num_directions = 2 if bidirectional else 1 \n",
    "    h = Tensor(np.zeros((num_layers * num_directions, batch_size, hidden_size)).astype(np.float32)) \n",
    "    c = Tensor(np.zeros((num_layers * num_directions, batch_size, hidden_size)).astype(np.float32)) \n",
    "    return h, c \n",
    "def stack_lstm_default_state(batch_size, hidden_size, num_layers, bidirectional): \n",
    "    \"\"\"init default input.\"\"\" \n",
    "    num_directions = 2 if bidirectional else 1\n",
    "    h_list = c_list = [] \n",
    "    for _ in range(num_layers): \n",
    "        h_list.append(Tensor(np.zeros((num_directions, batch_size, hidden_size)).astype(np.float32))) \n",
    "        c_list.append(Tensor(np.zeros((num_directions, batch_size, hidden_size)).astype(np.float32))) \n",
    "    h, c = tuple(h_list), tuple(c_list) \n",
    "    return h, c \n",
    "class StackLSTM(nn.Cell):\n",
    "    \"\"\" Stack multi-layers LSTM together. \"\"\" \n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 hidden_size, \n",
    "                 num_layers=1, \n",
    "                 has_bias=True, \n",
    "                 batch_first=False, \n",
    "                 dropout=0.0, \n",
    "                 bidirectional=False): \n",
    "        super(StackLSTM, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.batch_first = batch_first \n",
    "        self.transpose = ops.Transpose() \n",
    "        # direction number \n",
    "        num_directions = 2 if bidirectional else 1 \n",
    "        \n",
    "        # input_size list \n",
    "        input_size_list = [input_size] \n",
    "        for i in range(num_layers - 1): \n",
    "            input_size_list.append(hidden_size * num_directions) \n",
    "        # layers \n",
    "        layers = [] \n",
    "        for i in range(num_layers): \n",
    "            layers.append(nn.LSTMCell(input_size=input_size_list[i], \n",
    "                                      hidden_size=hidden_size, \n",
    "                                      has_bias=has_bias, \n",
    "                                      batch_first=batch_first, \n",
    "                                      bidirectional=bidirectional, \n",
    "                                      dropout=dropout)) \n",
    "        # weights \n",
    "        weights = [] \n",
    "        for i in range(num_layers): \n",
    "            # weight size \n",
    "            weight_size = (input_size_list[i] + hidden_size) * num_directions * hidden_size * 4 \n",
    "            if has_bias: \n",
    "                bias_size = num_directions * hidden_size * 4 \n",
    "                weight_size = weight_size + bias_size \n",
    "            # numpy weight \n",
    "            stdv = 1 / math.sqrt(hidden_size)\n",
    "            w_np = np.random.uniform(-stdv, stdv, (weight_size, 1, 1)).astype(np.float32) \n",
    "            # lstm weight \n",
    "            weights.append(Parameter(initializer(Tensor(w_np), w_np.shape), name=\"weight\" + str(i))) \n",
    "            #\n",
    "        self.lstms = layers \n",
    "        self.weight = ParameterTuple(tuple(weights)) \n",
    "    def construct(self, x, hx): \n",
    "        \"\"\"construct\"\"\" \n",
    "        if self.batch_first: \n",
    "            x = self.transpose(x, (1, 0, 2)) \n",
    "        # stack lstm \n",
    "        h, c = hx \n",
    "        hn = cn = None \n",
    "        for i in range(self.num_layers): \n",
    "            x, hn, cn, _, _ = self.lstms[i](x, h[i], c[i], self.weight[i]) \n",
    "        if self.batch_first: \n",
    "            x = self.transpose(x, (1, 0, 2)) \n",
    "        return x, (hn, cn) \n",
    "class SentimentNet(nn.Cell): \n",
    "    \"\"\"Sentiment network structure.\"\"\" \n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 embed_size, \n",
    "                 num_hiddens, \n",
    "                 num_layers, \n",
    "                 bidirectional, \n",
    "                 num_classes, \n",
    "                 weight, \n",
    "                 batch_size): \n",
    "        super(SentimentNet, self).__init__() \n",
    "        # Mapp words to vectors \n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_size, \n",
    "                                      embedding_table=weight) \n",
    "        self.embedding.embedding_table.requires_grad = False \n",
    "        self.trans = ops.Transpose() \n",
    "        self.perm = (1, 0, 2) \n",
    "        \n",
    "        if context.get_context(\"device_target\") in STACK_LSTM_DEVICE: \n",
    "            # stack lstm by user \n",
    "            self.encoder = StackLSTM(input_size=embed_size, \n",
    "                                     hidden_size=num_hiddens, \n",
    "                                     num_layers=num_layers, \n",
    "                                     has_bias=True, \n",
    "                                     bidirectional=bidirectional, \n",
    "                                     dropout=0.0) \n",
    "            self.h, self.c = stack_lstm_default_state(batch_size, num_hiddens, num_layers, bidirectional) \n",
    "        else:\n",
    "            # standard lstm\n",
    "            self.encoder = nn.LSTM(input_size=embed_size, \n",
    "                                   hidden_size=num_hiddens,\n",
    "                                   num_layers=num_layers, \n",
    "                                   has_bias=True, \n",
    "                                   bidirectional=bidirectional, \n",
    "                                   dropout=0.0) \n",
    "            self.h, self.c = lstm_default_state(batch_size, num_hiddens, num_layers, bidirectional) \n",
    "        self.concat = ops.Concat(1) \n",
    "        if bidirectional: \n",
    "            self.decoder = nn.Dense(num_hiddens * 4, num_classes) \n",
    "        else:\n",
    "            self.decoder = nn.Dense(num_hiddens * 2, num_classes) \n",
    "    def construct(self, inputs): \n",
    "        # inputï¼š(64,500,300) \n",
    "        embeddings = self.embedding(inputs) \n",
    "        embeddings = self.trans(embeddings, self.perm) \n",
    "        output, _ = self.encoder(embeddings, (self.h, self.c)) \n",
    "        # states[i] size(64,200) -> encoding.size(64,400) \n",
    "        encoding = self.concat((output[0], output[499])) \n",
    "        outputs = self.decoder(encoding) \n",
    "        return outputs \n",
    "embedding_table = np.loadtxt(os.path.join(args.preprocess_path, \"weight.txt\")).astype(np.float32) \n",
    "network = SentimentNet(vocab_size=embedding_table.shape[0], \n",
    "                       embed_size=cfg.embed_size, \n",
    "                       num_hiddens=cfg.num_hiddens, \n",
    "                       num_layers=cfg.num_layers, \n",
    "                       bidirectional=cfg.bidirectional, \n",
    "                       num_classes=cfg.num_classes, \n",
    "                       weight=Tensor(embedding_table), \n",
    "                       batch_size=cfg.batch_size) \n",
    "print(network.parameters_dict(recurse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026ef6e-c06e-49af-988b-7df20c881243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import Model \n",
    "from mindspore.train.callback import CheckpointConfig, ModelCheckpoint, TimeMonitor, LossMonitor \n",
    "from mindspore.nn import Accuracy \n",
    "from mindspore import nn \n",
    "os.system(\"rm -f {0}/*.ckpt {0}/*.meta\".format(args.ckpt_path)) \n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean') \n",
    "opt = nn.Momentum(network.trainable_params(), cfg.learning_rate, cfg.momentum) \n",
    "model = Model(network, loss, opt, {'acc': Accuracy()})\n",
    "loss_cb = LossMonitor(per_print_times=78) \n",
    "print(\"============== Starting Training ==============\") \n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps, \n",
    "                             keep_checkpoint_max=cfg.keep_checkpoint_max) \n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"lstm\", directory=args.ckpt_path, config=config_ck) \n",
    "time_cb = TimeMonitor(data_size=ds_train.get_dataset_size()) \n",
    "if args.device_target == \"CPU\": \n",
    "    model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb], dataset_sink_mode=False) \n",
    "else:\n",
    "    model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb]) \n",
    "print(\"============== Training Success ==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ede3e-9153-4f6c-a505-842df94df183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Testing ==============\n",
      "============== {'acc': 0.85625} ==============\n"
     ]
    }
   ],
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net \n",
    "args.ckpt_path_saved = f'{args.ckpt_path}/lstm-{cfg.num_epochs}_390.ckpt' \n",
    "print(\"============== Starting Testing ==============\") \n",
    "ds_eval = lstm_create_dataset(args.preprocess_path, cfg.batch_size, training=False) \n",
    "param_dict = load_checkpoint(args.ckpt_path_saved) \n",
    "load_param_into_net(network, param_dict) \n",
    "if args.device_target == \"CPU\": \n",
    "    acc = model.eval(ds_eval, dataset_sink_mode=False) \n",
    "else:\n",
    "    acc = model.eval(ds_eval) \n",
    "print(\"============== {} ==============\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
